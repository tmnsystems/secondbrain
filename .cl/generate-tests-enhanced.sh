#!/bin/bash
# Enhanced Test Generation Script for SecondBrain
# Creates comprehensive test scaffolding with intelligent source analysis

# Default values
VERBOSE=false
TEST_FRAMEWORK="jest"
COVERAGE_THRESHOLD=85
GENERATE_SNAPSHOTS=false
AUTO_ANALYZE=true
MOCK_DEPENDENCIES=true
INTEGRATION_TESTS=false

# Parse arguments
while [[ $# -gt 0 ]]; do
  case $1 in
    -t|--test-framework)
      if [ -n "$2" ] && [ ${2:0:1} != "-" ]; then
        TEST_FRAMEWORK=$2
        shift 2
      else
        echo "Error: Argument for $1 is missing" >&2
        exit 1
      fi
      ;;
    -c|--coverage-threshold)
      if [ -n "$2" ] && [ ${2:0:1} != "-" ]; then
        COVERAGE_THRESHOLD=$2
        shift 2
      else
        echo "Error: Argument for $1 is missing" >&2
        exit 1
      fi
      ;;
    -s|--snapshots)
      GENERATE_SNAPSHOTS=true
      shift
      ;;
    -n|--no-analysis)
      AUTO_ANALYZE=false
      shift
      ;;
    -m|--no-mocks)
      MOCK_DEPENDENCIES=false
      shift
      ;;
    -i|--integration)
      INTEGRATION_TESTS=true
      shift
      ;;
    -v|--verbose)
      VERBOSE=true
      shift
      ;;
    *)
      TARGET_DIR=$1
      shift
      ;;
  esac
done

# Check if target directory is provided
if [ -z "$TARGET_DIR" ]; then
  echo "Usage: $0 <target_directory> [options]"
  echo ""
  echo "Options:"
  echo "  -t, --test-framework <framework>   Specify test framework (jest, mocha, pytest) [default: jest]"
  echo "  -c, --coverage-threshold <number>  Set coverage threshold percentage [default: 85]"
  echo "  -s, --snapshots                    Generate snapshot tests for components"
  echo "  -n, --no-analysis                  Skip auto-analysis of source files"
  echo "  -m, --no-mocks                     Skip automatic mock generation"
  echo "  -i, --integration                  Generate integration tests in addition to unit tests"
  echo "  -v, --verbose                      Enable verbose output"
  echo ""
  echo "Example: $0 /Volumes/Envoy/SecondBrain/agents/planner --test-framework jest --snapshots --integration"
  exit 1
fi

TEST_DIR="${TARGET_DIR}/tests"
UNIT_DIR="${TEST_DIR}/unit"
INTEGRATION_DIR="${TEST_DIR}/integration"
SNAPSHOT_DIR="${TEST_DIR}/snapshots"
MOCK_DIR="${TEST_DIR}/mocks"

# Create test directories
mkdir -p "$UNIT_DIR"
if $INTEGRATION_TESTS; then
  mkdir -p "$INTEGRATION_DIR"
fi
if $GENERATE_SNAPSHOTS; then
  mkdir -p "$SNAPSHOT_DIR"
fi
if $MOCK_DEPENDENCIES; then
  mkdir -p "$MOCK_DIR"
fi

if $VERBOSE; then
  echo "Generating tests for: $TARGET_DIR"
  echo "Using test framework: $TEST_FRAMEWORK"
  echo "Coverage threshold: $COVERAGE_THRESHOLD%"
  echo "Generate snapshots: $GENERATE_SNAPSHOTS"
  echo "Auto-analyze source: $AUTO_ANALYZE"
  echo "Mock dependencies: $MOCK_DEPENDENCIES"
  echo "Generate integration tests: $INTEGRATION_TESTS"
  echo "---------------------------------"
fi

# Function to extract imports from a file
extract_imports() {
  local file=$1
  local extension="${file##*.}"
  
  if [ "$extension" = "js" ] || [ "$extension" = "ts" ]; then
    # Extract import statements for JS/TS
    grep -E "import .* from .*" "$file" | sed -E 's/import (.*) from .*/\1/'
  elif [ "$extension" = "py" ]; then
    # Extract import statements for Python
    grep -E "^import |^from " "$file" | sed -E 's/import (.*)/\1/' | sed -E 's/from (.*) import .*/\1/'
  fi
}

# Function to extract exported functions and classes
extract_exports() {
  local file=$1
  local extension="${file##*.}"
  
  if [ "$extension" = "js" ] || [ "$extension" = "ts" ]; then
    # Extract export declarations for JS/TS
    grep -E "export (class|function|const|interface|type) [a-zA-Z0-9_]+" "$file" | sed -E 's/export (class|function|const|interface|type) ([a-zA-Z0-9_]+).*/\2/'
  elif [ "$extension" = "py" ]; then
    # Extract class and function definitions for Python
    grep -E "^class |^def " "$file" | sed -E 's/class ([a-zA-Z0-9_]+).*/\1/' | sed -E 's/def ([a-zA-Z0-9_]+).*/\1/'
  fi
}

# Function to generate mock file
generate_mock() {
  local import_name=$1
  local mock_file="${MOCK_DIR}/${import_name}.mock.ts"
  
  # Skip if mock already exists
  if [ -f "$mock_file" ]; then
    if $VERBOSE; then
      echo "Mock for $import_name already exists, skipping"
    fi
    return
  fi
  
  if $VERBOSE; then
    echo "Generating mock for: $import_name"
  fi
  
  # Create mock file
  cat > "$mock_file" << EOF
/**
 * Mock for ${import_name}
 * Auto-generated by SecondBrain test generator
 */

export const ${import_name}Mock = {
  // Add mock implementation properties and methods here
};

export default ${import_name}Mock;
EOF
}

# Find all source files in the target directory
if [ "$TEST_FRAMEWORK" = "pytest" ]; then
  FILES=$(find "$TARGET_DIR" -maxdepth 2 -type f -name "*.py" | grep -v "test_\|__pycache__\|\.pyc$")
else
  FILES=$(find "$TARGET_DIR" -maxdepth 2 -type f -name "*.js" -o -name "*.ts" | grep -v "test\|spec\|node_modules\|\.d\.ts$")
fi

# For each file, create test files
for FILE in $FILES; do
  FILENAME=$(basename "$FILE")
  BASENAME="${FILENAME%.*}"
  EXTENSION="${FILENAME##*.}"
  UNIT_TEST_FILE="$UNIT_DIR/${BASENAME}.test.${EXTENSION}"
  INTEGRATION_TEST_FILE="$INTEGRATION_DIR/${BASENAME}.integration.test.${EXTENSION}"
  SNAPSHOT_TEST_FILE="$SNAPSHOT_DIR/${BASENAME}.snapshot.test.${EXTENSION}"
  
  # Extract imports and exports if auto-analysis is enabled
  IMPORTS=()
  EXPORTS=()
  if $AUTO_ANALYZE; then
    mapfile -t IMPORTS < <(extract_imports "$FILE")
    mapfile -t EXPORTS < <(extract_exports "$FILE")
    
    if $VERBOSE; then
      echo "Analysis of $BASENAME:"
      echo "  Found ${#EXPORTS[@]} exportable items"
      echo "  Found ${#IMPORTS[@]} imports"
    fi
    
    # Generate mocks for dependencies
    if $MOCK_DEPENDENCIES; then
      for IMPORT in "${IMPORTS[@]}"; do
        generate_mock "$IMPORT"
      done
    fi
  fi
  
  # Skip if unit test file already exists
  if [ -f "$UNIT_TEST_FILE" ]; then
    if $VERBOSE; then
      echo "Skipping $BASENAME - unit test already exists"
    fi
  else
    echo "Generating unit test for: $BASENAME"
    
    # Create test scaffold based on framework
    if [ "$TEST_FRAMEWORK" = "jest" ]; then
      # Create Jest test scaffold
      cat > "$UNIT_TEST_FILE" << EOF
/**
 * Unit tests for ${BASENAME}
 * Auto-generated by SecondBrain test generator
 */

import { ${BASENAME} } from '../${FILENAME}';
EOF

      # Add imports for mocks if available
      if $MOCK_DEPENDENCIES && [ ${#IMPORTS[@]} -gt 0 ]; then
        for IMPORT in "${IMPORTS[@]}"; do
          echo "import { ${IMPORT}Mock } from '../mocks/${IMPORT}.mock';" >> "$UNIT_TEST_FILE"
        done
        echo "" >> "$UNIT_TEST_FILE"
        # Add jest.mock calls
        for IMPORT in "${IMPORTS[@]}"; then
          echo "jest.mock('${IMPORT}', () => ${IMPORT}Mock);" >> "$UNIT_TEST_FILE"
        done
      fi
      
      # Add test suite
      cat >> "$UNIT_TEST_FILE" << EOF

describe('${BASENAME}', () => {
  beforeEach(() => {
    // Setup before each test
    jest.clearAllMocks();
  });

  afterEach(() => {
    // Cleanup after each test
  });

EOF

      # Add tests for each exported item
      if $AUTO_ANALYZE && [ ${#EXPORTS[@]} -gt 0 ]; then
        for EXPORT in "${EXPORTS[@]}"; do
          cat >> "$UNIT_TEST_FILE" << EOF
  describe('${EXPORT}', () => {
    test('should initialize correctly', () => {
      // Test initialization
      // TODO: Implement test
    });

    test('should perform its main functionality correctly', () => {
      // Test main functionality
      // TODO: Implement test
    });

    test('should handle errors appropriately', () => {
      // Test error handling
      // TODO: Implement test
    });

    test('should handle edge cases', () => {
      // Test edge cases
      // TODO: Implement test
    });
  });

EOF
        done
      else
        # Default tests if no exports were found
        cat >> "$UNIT_TEST_FILE" << EOF
  test('should initialize correctly', () => {
    // Test initialization
    const instance = new ${BASENAME}();
    expect(instance).toBeDefined();
  });

  test('should perform its main function correctly', () => {
    // Test main functionality
    const instance = new ${BASENAME}();
    // Add assertions here
    // TODO: Implement test
  });

  test('should handle errors appropriately', () => {
    // Test error handling
    const instance = new ${BASENAME}();
    // Add error scenario and assertions
    // TODO: Implement test
  });

  test('should handle edge cases', () => {
    // Test edge cases
    const instance = new ${BASENAME}();
    // Add edge case testing
    // TODO: Implement test
  });
EOF
      fi
      
      # Close the describe block
      echo "});" >> "$UNIT_TEST_FILE"
      
    elif [ "$TEST_FRAMEWORK" = "mocha" ]; then
      # Create Mocha test scaffold
      cat > "$UNIT_TEST_FILE" << EOF
/**
 * Unit tests for ${BASENAME}
 * Auto-generated by SecondBrain test generator
 */

import { expect } from 'chai';
import { ${BASENAME} } from '../${FILENAME}';
import sinon from 'sinon';

describe('${BASENAME}', () => {
  beforeEach(() => {
    // Setup before each test
  });

  afterEach(() => {
    // Cleanup after each test
    sinon.restore();
  });

EOF

      # Add tests for each exported item
      if $AUTO_ANALYZE && [ ${#EXPORTS[@]} -gt 0 ]; then
        for EXPORT in "${EXPORTS[@]}"; then
          cat >> "$UNIT_TEST_FILE" << EOF
  describe('${EXPORT}', () => {
    it('should initialize correctly', () => {
      // Test initialization
      // TODO: Implement test
    });

    it('should perform its main functionality correctly', () => {
      // Test main functionality
      // TODO: Implement test
    });

    it('should handle errors appropriately', () => {
      // Test error handling
      // TODO: Implement test
    });

    it('should handle edge cases', () => {
      // Test edge cases
      // TODO: Implement test
    });
  });

EOF
        done
      else
        # Default tests if no exports were found
        cat >> "$UNIT_TEST_FILE" << EOF
  it('should initialize correctly', () => {
    // Test initialization
    const instance = new ${BASENAME}();
    expect(instance).to.exist;
  });

  it('should perform its main function correctly', () => {
    // Test main functionality
    const instance = new ${BASENAME}();
    // Add assertions here
    // TODO: Implement test
  });

  it('should handle errors appropriately', () => {
    // Test error handling
    const instance = new ${BASENAME}();
    // Add error scenario and assertions
    // TODO: Implement test
  });

  it('should handle edge cases', () => {
    // Test edge cases
    const instance = new ${BASENAME}();
    // Add edge case testing
    // TODO: Implement test
  });
EOF
      fi
      
      # Close the describe block
      echo "});" >> "$UNIT_TEST_FILE"
      
    elif [ "$TEST_FRAMEWORK" = "pytest" ]; then
      # Create Pytest test scaffold
      UNIT_TEST_FILE="$UNIT_DIR/test_${BASENAME}.py"
      
      cat > "$UNIT_TEST_FILE" << EOF
"""
Unit tests for ${BASENAME}
Auto-generated by SecondBrain test generator
"""

import pytest
from ..${BASENAME} import ${BASENAME}

@pytest.fixture
def ${BASENAME.toLowerCase()}_instance():
    """Create a ${BASENAME} instance for testing."""
    return ${BASENAME}()

EOF

      # Add tests for each exported item
      if $AUTO_ANALYZE && [ ${#EXPORTS[@]} -gt 0 ]; then
        for EXPORT in "${EXPORTS[@]}"; then
          cat >> "$UNIT_TEST_FILE" << EOF
class Test${EXPORT}:
    """Tests for the ${EXPORT} class/function."""
    
    def test_initialization(self, ${BASENAME.toLowerCase()}_instance):
        """Test that the ${EXPORT} initializes correctly."""
        # TODO: Implement test
        assert ${BASENAME.toLowerCase()}_instance is not None
    
    def test_main_functionality(self, ${BASENAME.toLowerCase()}_instance):
        """Test the main functionality of ${EXPORT}."""
        # TODO: Implement test
        pass
    
    def test_error_handling(self, ${BASENAME.toLowerCase()}_instance):
        """Test error handling in ${EXPORT}."""
        # TODO: Implement test
        pass
    
    def test_edge_cases(self, ${BASENAME.toLowerCase()}_instance):
        """Test edge cases for ${EXPORT}."""
        # TODO: Implement test
        pass

EOF
        done
      else
        # Default tests if no exports were found
        cat >> "$UNIT_TEST_FILE" << EOF
def test_initialization(${BASENAME.toLowerCase()}_instance):
    """Test that the ${BASENAME} initializes correctly."""
    assert ${BASENAME.toLowerCase()}_instance is not None

def test_main_functionality(${BASENAME.toLowerCase()}_instance):
    """Test the main functionality of ${BASENAME}."""
    # TODO: Implement test
    pass

def test_error_handling(${BASENAME.toLowerCase()}_instance):
    """Test error handling in ${BASENAME}."""
    # TODO: Implement test
    pass

def test_edge_cases(${BASENAME.toLowerCase()}_instance):
    """Test edge cases for ${BASENAME}."""
    # TODO: Implement test
    pass
EOF
      fi
    else
      echo "Unsupported test framework: $TEST_FRAMEWORK"
      exit 1
    fi
  fi
  
  # Generate integration tests if requested
  if $INTEGRATION_TESTS && [ ! -f "$INTEGRATION_TEST_FILE" ]; then
    echo "Generating integration test for: $BASENAME"
    
    if [ "$TEST_FRAMEWORK" = "jest" ]; then
      cat > "$INTEGRATION_TEST_FILE" << EOF
/**
 * Integration tests for ${BASENAME}
 * Auto-generated by SecondBrain test generator
 */

import { ${BASENAME} } from '../${FILENAME}';

describe('${BASENAME} Integration', () => {
  beforeAll(() => {
    // Setup before all integration tests
  });

  afterAll(() => {
    // Cleanup after all integration tests
  });

  test('should integrate with dependencies correctly', () => {
    // Test integration with dependencies
    // TODO: Implement test
  });

  test('should handle end-to-end workflow correctly', () => {
    // Test end-to-end workflow
    // TODO: Implement test
  });
});
EOF
    elif [ "$TEST_FRAMEWORK" = "mocha" ]; then
      cat > "$INTEGRATION_TEST_FILE" << EOF
/**
 * Integration tests for ${BASENAME}
 * Auto-generated by SecondBrain test generator
 */

import { expect } from 'chai';
import { ${BASENAME} } from '../${FILENAME}';

describe('${BASENAME} Integration', () => {
  before(() => {
    // Setup before all integration tests
  });

  after(() => {
    // Cleanup after all integration tests
  });

  it('should integrate with dependencies correctly', () => {
    // Test integration with dependencies
    // TODO: Implement test
  });

  it('should handle end-to-end workflow correctly', () => {
    // Test end-to-end workflow
    // TODO: Implement test
  });
});
EOF
    elif [ "$TEST_FRAMEWORK" = "pytest" ]; then
      INTEGRATION_TEST_FILE="$INTEGRATION_DIR/test_${BASENAME}_integration.py"
      cat > "$INTEGRATION_TEST_FILE" << EOF
"""
Integration tests for ${BASENAME}
Auto-generated by SecondBrain test generator
"""

import pytest
from ..${BASENAME} import ${BASENAME}

@pytest.fixture(scope="module")
def ${BASENAME.toLowerCase()}_setup():
    """Setup for integration tests."""
    # TODO: Implement setup
    yield ${BASENAME}()
    # TODO: Implement teardown

def test_dependency_integration(${BASENAME.toLowerCase()}_setup):
    """Test integration with dependencies."""
    # TODO: Implement test
    pass

def test_end_to_end_workflow(${BASENAME.toLowerCase()}_setup):
    """Test end-to-end workflow."""
    # TODO: Implement test
    pass
EOF
    fi
  fi
  
  # Generate snapshot tests if requested
  if $GENERATE_SNAPSHOTS && [ ! -f "$SNAPSHOT_TEST_FILE" ] && [ "$TEST_FRAMEWORK" = "jest" ]; then
    echo "Generating snapshot test for: $BASENAME"
    
    cat > "$SNAPSHOT_TEST_FILE" << EOF
/**
 * Snapshot tests for ${BASENAME}
 * Auto-generated by SecondBrain test generator
 */

import { ${BASENAME} } from '../${FILENAME}';

describe('${BASENAME} Snapshots', () => {
  test('should match snapshot for default state', () => {
    // Create instance with default settings
    const instance = new ${BASENAME}();
    
    // Convert to serializable format if needed
    const serialized = JSON.stringify(instance);
    
    // Verify snapshot
    expect(serialized).toMatchSnapshot();
  });

  test('should match snapshot for common configurations', () => {
    // Create instance with common configurations
    const instance = new ${BASENAME}();
    // TODO: Configure instance
    
    // Convert to serializable format if needed
    const serialized = JSON.stringify(instance);
    
    // Verify snapshot
    expect(serialized).toMatchSnapshot();
  });
});
EOF
  fi
done

# Create test configuration files
if [ "$TEST_FRAMEWORK" = "jest" ] && [ ! -f "${TARGET_DIR}/jest.config.js" ]; then
  cat > "${TARGET_DIR}/jest.config.js" << EOF
/**
 * Jest configuration for ${TARGET_DIR}
 * Auto-generated by SecondBrain test generator
 */

module.exports = {
  preset: 'ts-jest',
  testEnvironment: 'node',
  testMatch: [
    '**/tests/unit/**/*.test.ts',
    '**/tests/integration/**/*.integration.test.ts',
    '**/tests/snapshots/**/*.snapshot.test.ts'
  ],
  collectCoverage: true,
  collectCoverageFrom: [
    '**/*.{js,ts}',
    '!**/node_modules/**',
    '!**/tests/**',
    '!**/coverage/**',
    '!**/dist/**',
    '!**/*.config.js'
  ],
  coverageDirectory: 'coverage',
  coverageReporters: ['text', 'lcov', 'html'],
  coverageThreshold: {
    global: {
      branches: ${COVERAGE_THRESHOLD},
      functions: ${COVERAGE_THRESHOLD},
      lines: ${COVERAGE_THRESHOLD},
      statements: ${COVERAGE_THRESHOLD}
    }
  },
  verbose: true,
  testTimeout: 10000
};
EOF

  # Create package.json test scripts if it exists
  if [ -f "${TARGET_DIR}/package.json" ]; then
    # Use temporary file for sed in-place replacement that works on both Linux and macOS
    sed -i.bak '/"scripts":/,/}/s/}/,\n    "test": "jest",\n    "test:watch": "jest --watch",\n    "test:coverage": "jest --coverage"}/' "${TARGET_DIR}/package.json"
    rm "${TARGET_DIR}/package.json.bak"
  fi

elif [ "$TEST_FRAMEWORK" = "mocha" ] && [ ! -f "${TARGET_DIR}/.mocharc.js" ]; then
  cat > "${TARGET_DIR}/.mocharc.js" << EOF
/**
 * Mocha configuration for ${TARGET_DIR}
 * Auto-generated by SecondBrain test generator
 */

module.exports = {
  require: ['ts-node/register'],
  extension: ['ts'],
  spec: [
    'tests/unit/**/*.test.ts',
    'tests/integration/**/*.integration.test.ts'
  ],
  timeout: 10000,
  recursive: true
};
EOF

  # Create nyc (istanbul) config for coverage
  cat > "${TARGET_DIR}/.nycrc.json" << EOF
{
  "extends": "@istanbuljs/nyc-config-typescript",
  "all": true,
  "check-coverage": true,
  "branches": ${COVERAGE_THRESHOLD},
  "lines": ${COVERAGE_THRESHOLD},
  "functions": ${COVERAGE_THRESHOLD},
  "statements": ${COVERAGE_THRESHOLD},
  "include": [
    "**/*.ts"
  ],
  "exclude": [
    "**/*.d.ts",
    "coverage/**",
    "tests/**",
    "**/*.test.ts",
    "**/*.config.js"
  ],
  "reporter": [
    "text",
    "lcov",
    "html"
  ]
}
EOF

  # Create package.json test scripts if it exists
  if [ -f "${TARGET_DIR}/package.json" ]; then
    # Use temporary file for sed in-place replacement that works on both Linux and macOS
    sed -i.bak '/"scripts":/,/}/s/}/,\n    "test": "mocha",\n    "test:watch": "mocha --watch",\n    "test:coverage": "nyc mocha"}/' "${TARGET_DIR}/package.json"
    rm "${TARGET_DIR}/package.json.bak"
  fi

elif [ "$TEST_FRAMEWORK" = "pytest" ] && [ ! -f "${TARGET_DIR}/pytest.ini" ]; then
  cat > "${TARGET_DIR}/pytest.ini" << EOF
[pytest]
testpaths = tests/unit tests/integration
python_files = test_*.py
python_classes = Test*
python_functions = test_*
addopts = --verbose --cov=. --cov-report=term --cov-report=html
cov_report = term-missing
cov_fail_under = ${COVERAGE_THRESHOLD}
EOF

  # Create requirements-test.txt if it doesn't exist
  if [ ! -f "${TARGET_DIR}/requirements-test.txt" ]; then
    cat > "${TARGET_DIR}/requirements-test.txt" << EOF
pytest>=7.0.0
pytest-cov>=4.0.0
pytest-mock>=3.10.0
EOF
  fi
fi

# Create a README for tests
cat > "${TEST_DIR}/README.md" << EOF
# Tests for ${TARGET_DIR##*/}

## Directory Structure

- \`unit/\`: Unit tests for individual components
${INTEGRATION_TESTS && "- \`integration/\`: Integration tests for component interactions" || ""}
${GENERATE_SNAPSHOTS && "- \`snapshots/\`: Snapshot tests for component outputs" || ""}
${MOCK_DEPENDENCIES && "- \`mocks/\`: Mock implementations of dependencies" || ""}

## Running Tests

${TEST_FRAMEWORK == "jest" && "```bash
# Run all tests
npm test

# Run tests in watch mode
npm run test:watch

# Run tests with coverage report
npm run test:coverage
```" || ""}

${TEST_FRAMEWORK == "mocha" && "```bash
# Run all tests
npm test

# Run tests in watch mode
npm run test:watch

# Run tests with coverage report
npm run test:coverage
```" || ""}

${TEST_FRAMEWORK == "pytest" && "```bash
# Install test dependencies
pip install -r requirements-test.txt

# Run all tests
pytest

# Run tests with coverage report
pytest --cov

# Run specific test file
pytest tests/unit/test_specific_file.py
```" || ""}

## Coverage Requirements

Coverage threshold is set to ${COVERAGE_THRESHOLD}% for:
- Statements
- Branches
- Functions
- Lines

## Best Practices

1. Follow the test structure provided in the scaffolding
2. Add meaningful assertions to each test case
3. Test both happy paths and error cases
4. Use mocks appropriately to isolate the unit under test
5. Maintain test independence (tests should not depend on each other)
6. Keep tests fast and focused

## Generating New Tests

Run the following command to generate tests for new components:

\`\`\`bash
/Volumes/Envoy/SecondBrain/.cl/generate-tests-enhanced.sh /path/to/component ${TEST_FRAMEWORK == "jest" && "--test-framework jest" || TEST_FRAMEWORK == "mocha" && "--test-framework mocha" || "--test-framework pytest"}
\`\`\`
EOF

# Output summary
echo "Test generation complete!"
echo "Generated $(find "$UNIT_DIR" -type f | wc -l | tr -d ' ') unit tests"
if $INTEGRATION_TESTS; then
  echo "Generated $(find "$INTEGRATION_DIR" -type f | wc -l | tr -d ' ') integration tests"
fi
if $GENERATE_SNAPSHOTS; then
  echo "Generated $(find "$SNAPSHOT_DIR" -type f | wc -l | tr -d ' ') snapshot tests"
fi
if $MOCK_DEPENDENCIES; then
  echo "Generated $(find "$MOCK_DIR" -type f | wc -l | tr -d ' ') mock files"
fi
echo "Test files are located in: $TEST_DIR"
echo "Configuration files have been created for $TEST_FRAMEWORK"
echo "Coverage threshold set to: $COVERAGE_THRESHOLD%"